{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                0     \\\n",
      "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 52, 192, 115, 27, ...   \n",
      "\n",
      "                                                1     \\\n",
      "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 74, 143, 82, 9, 0,...   \n",
      "\n",
      "                                                2     \\\n",
      "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 60, 49, 0, 0...   \n",
      "\n",
      "                                                3     \\\n",
      "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 18, 23, 155, 156, ...   \n",
      "\n",
      "                                                4     \\\n",
      "0  [0, 0, 0, 0, 0, 0, 0, 26, 64, 134, 75, 1, 0, 0...   \n",
      "\n",
      "                                                5     \\\n",
      "0  [0, 0, 0, 0, 0, 0, 2, 3, 0, 0, 0, 191, 202, 17...   \n",
      "\n",
      "                                                6     \\\n",
      "0  [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 119, 26, 0, ...   \n",
      "\n",
      "                                                7     \\\n",
      "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 27, 67, 42, 0, 0, ...   \n",
      "\n",
      "                                                8     \\\n",
      "0  [0, 0, 0, 0, 0, 0, 0, 0, 106, 172, 185, 139, 9...   \n",
      "\n",
      "                                                9     \\\n",
      "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 8, 46, 65, 44, 43,...   \n",
      "\n",
      "                         ...                          \\\n",
      "0                        ...                           \n",
      "\n",
      "                                                1990  \\\n",
      "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 90, 82, 56, ...   \n",
      "\n",
      "                                                1991  \\\n",
      "0  [0, 0, 0, 0, 0, 0, 0, 43, 67, 130, 165, 100, 4...   \n",
      "\n",
      "                                                1992  \\\n",
      "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
      "\n",
      "                                                1993  \\\n",
      "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 94, 126, ...   \n",
      "\n",
      "                                                1994  \\\n",
      "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 36, 100, 0, ...   \n",
      "\n",
      "                                                1995  \\\n",
      "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
      "\n",
      "                                                1996  \\\n",
      "0  [0, 0, 0, 0, 0, 0, 0, 3, 1, 0, 0, 48, 180, 143...   \n",
      "\n",
      "                                                1997  \\\n",
      "0  [0, 0, 0, 0, 0, 0, 7, 42, 119, 166, 27, 0, 0, ...   \n",
      "\n",
      "                                                1998  \\\n",
      "0  [0, 0, 0, 0, 0, 0, 0, 1, 3, 2, 0, 12, 150, 127...   \n",
      "\n",
      "                                                1999  \n",
      "0  [0, 0, 0, 0, 0, 0, 0, 3, 2, 0, 0, 0, 53, 153, ...  \n",
      "\n",
      "[1 rows x 2000 columns]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "objects = []\n",
    "with (open(\"test_image.pkl\", \"rb\")) as openfile:\n",
    "    while True:\n",
    "        try:\n",
    "            objects.append(pickle.load(openfile))\n",
    "        except EOFError:\n",
    "            break\n",
    "df=pd.DataFrame(data=objects,columns=None)\n",
    "df.to_csv('data.csv')\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                0     \\\n",
      "0  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 41, 188, 103, 5...   \n",
      "\n",
      "                                                1     \\\n",
      "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 22, 118, 24, 0, 0,...   \n",
      "\n",
      "                                                2     \\\n",
      "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
      "\n",
      "                                                3     \\\n",
      "0  [0, 0, 0, 0, 0, 0, 0, 11, 142, 200, 106, 0, 0,...   \n",
      "\n",
      "                                                4     \\\n",
      "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 19, 4, 0, 0,...   \n",
      "\n",
      "                                                5     \\\n",
      "0  [0, 0, 0, 0, 0, 0, 0, 0, 58, 121, 218, 110, 58...   \n",
      "\n",
      "                                                6     \\\n",
      "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 42, 110, 1, 0, 0, ...   \n",
      "\n",
      "                                                7     \\\n",
      "0  [0, 0, 0, 0, 0, 0, 0, 0, 39, 90, 135, 200, 132...   \n",
      "\n",
      "                                                8     \\\n",
      "0  [0, 0, 0, 0, 0, 0, 0, 73, 143, 149, 176, 135, ...   \n",
      "\n",
      "                                                9     \\\n",
      "0  [0, 0, 0, 0, 0, 0, 0, 96, 155, 0, 0, 1, 0, 0, ...   \n",
      "\n",
      "                         ...                          \\\n",
      "0                        ...                           \n",
      "\n",
      "                                                7990  \\\n",
      "0  [0, 0, 0, 0, 0, 1, 0, 1, 2, 0, 0, 47, 48, 65, ...   \n",
      "\n",
      "                                                7991  \\\n",
      "0  [0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, ...   \n",
      "\n",
      "                                                7992  \\\n",
      "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 130, 120, 0, 0, 0,...   \n",
      "\n",
      "                                                7993  \\\n",
      "0  [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 95, 130, 47,...   \n",
      "\n",
      "                                                7994  \\\n",
      "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 41, 92, 105,...   \n",
      "\n",
      "                                                7995  \\\n",
      "0  [0, 0, 0, 0, 1, 3, 0, 0, 90, 178, 157, 82, 59,...   \n",
      "\n",
      "                                                7996  \\\n",
      "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 78, 150, 6, 0, ...   \n",
      "\n",
      "                                                7997  \\\n",
      "0  [0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 198, 199, 18...   \n",
      "\n",
      "                                                7998  \\\n",
      "0  [0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 103, 146, 88...   \n",
      "\n",
      "                                                7999  \n",
      "0  [0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 120, 205,...  \n",
      "\n",
      "[1 rows x 8000 columns]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "objects = []\n",
    "with (open(\"train_image.pkl\", \"rb\")) as openfile:\n",
    "    while True:\n",
    "        try:\n",
    "            objects.append(pickle.load(openfile))\n",
    "        except EOFError:\n",
    "            break\n",
    "df=pd.DataFrame(data=objects,columns=None)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0     1     2     3     4     5     6     7     8     9     ...   7990  \\\n",
      "0     0     0     0     0     0     0     0     0     0     0  ...      6   \n",
      "\n",
      "   7991  7992  7993  7994  7995  7996  7997  7998  7999  \n",
      "0     6     6     6     6     6     6     6     6     6  \n",
      "\n",
      "[1 rows x 8000 columns]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "objects = []\n",
    "with (open(\"train_label.pkl\", \"rb\")) as openfile:\n",
    "    while True:\n",
    "        try:\n",
    "            objects.append(pickle.load(openfile))\n",
    "        except EOFError:\n",
    "            break\n",
    "df=pd.DataFrame(data=objects,columns=None)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "No module named 'tensorflow.python'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b35609a38282>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# fix random seed for reproducibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;32melif\u001b[0m \u001b[0m_BACKEND\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tensorflow'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Using TensorFlow backend.\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtensorflow_backend\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unknown backend: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_BACKEND\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmoving_averages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'tensorflow.python'"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy\n",
    "import pickle\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)\n",
    "\n",
    "pickle_in = open(\"test_image.pkl\",\"rb\")\n",
    "X = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"train_label.pkl\",\"rb\")\n",
    "y = pickle.load(pickle_in)\n",
    "\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# Fit the model\n",
    "model.fit(X, Y, epochs=150, batch_size=10)\n",
    "# evaluate the model\n",
    "scores = model.evaluate(X, Y)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-f0c441fc0e74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# unpacks images to x_train/x_test and labels to y_train/y_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# scales data between 0 and 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# scales data between 0 and 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'keras'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "import pickle         # deep learning library. Tensors are just multi-dimensional arrays\n",
    "\n",
    "#mnist = tf.keras.datasets.mnist  # mnist is a dataset of 28x28 images of handwritten digits and their labels\n",
    "#(x_train, y_train),(x_test, y_test) = mnist.load_data() \n",
    "pickle_in = open(\"train_image.pkl\",\"rb\")\n",
    "x_train = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"train_label.pkl\",\"rb\")\n",
    "y_train = pickle.load(pickle_in)\n",
    "pickle_in = open(\"test_image.pkl\",\"rb\")\n",
    "x_test = pickle.load(pickle_in)\n",
    "y_test = y_train\n",
    "\n",
    "# unpacks images to x_train/x_test and labels to y_train/y_test\n",
    "\n",
    "x_train = tf.keras.utils.normalize(x_train, axis=1)  # scales data between 0 and 1\n",
    "x_test = tf.keras.utils.normalize(x_test, axis=1)  # scales data between 0 and 1\n",
    "\n",
    "model = tf.keras.models.Sequential()  # a basic feed-forward model\n",
    "model.add(tf.keras.layers.Flatten())  # takes our 28x28 and makes it 1x784\n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))  # a simple fully-connected layer, 128 units, relu activation\n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))  # a simple fully-connected layer, 128 units, relu activation\n",
    "model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))  # our output layer. 10 units for 10 classes. Softmax for probability distribution\n",
    "\n",
    "model.compile(optimizer='adam',  # Good default optimizer to start with\n",
    "              loss='sparse_categorical_crossentropy',  # how will we calculate our \"error.\" Neural network aims to minimize loss.\n",
    "              metrics=['accuracy'])  # what to track\n",
    "\n",
    "model.fit(x_train, y_train, epochs=3)  # train the model\n",
    "\n",
    "val_loss, val_acc = model.evaluate(x_test, y_test)  # evaluate the out of sample data with model\n",
    "print(val_loss)  # model's loss (error)\n",
    "print(val_acc)  # model's accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
